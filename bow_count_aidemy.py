from gensim import corpora
from janome.tokenizer import Tokenizer

text1 = "機械学習はそもそもなぜ大きく注目されるのでしょうか。主な理由の一つとして、「 人間では到底実現不可能な時間で、大量のデータから自動的に短時間で正確な結果を得ることができる。 」ことが挙げられます。機械学習は、大量のデータからパターンを読み取り、問題を解決します。大量のデータを人力で解決するとなると、非常にコストがかかり現実的ではありません。以上の理由から、画像、音声、マーケティング、自然言語、医療など様々な分野において真価を発揮し、今日機械学習が大変注目を集めています。さらに、時代とともに、コンピュータの処理速度が向上し豊富なデータの解析に耐えうるデバイスが登場したのもその要因の一つでしょう。さて、最近「人工知能(AI)」「機械学習(マシンラーニング)」「深層学習(ディープラーニング)」など、様々な技術が挙げられています。こうした概念の関係性を以下の図に示します。上記の図からも分かるように、人工知能(AI)はかなり広範囲の言葉です。例えば、ひたすら条件を並べて分類するようなアルゴリズムも人工知能と言われます。(If-Then形式の知識表現アルゴリズムなどと呼ばれることもあります。)こうした手法は、昨今話題の技術とは言いにくいので、Aidemyでは取り扱いません。ここからは、「深層学習を含む機械学習(ディープラーニング)」を概観していきましょう。"

text2 = "そもそも機械学習の言葉の意味はなんでしょうか。簡単に言うと、機械学習とは「 データから反復的に学習し、そこに潜むパターンを探し出すこと。 」と言えます。データに潜むパターンとはなんでしょうか。少し、考えてみましょう。人間は、目の中にある網膜から光の信号を受け取り、瞳に何が写っているか高速に認識することができます。りんごやみかんといった果物や、机や椅子といった家具を瞬時に見分けることができ、りんごを椅子と間違うことはありません。なぜ、間違えないのでしょうか。それは、りんごと椅子との間に特徴(パターン)の違いがあるからです。りんごと椅子、それぞれにあるパターンが存在します。椅子は四角でりんごは丸い、これも一つのパターンです。りんごは赤色で、椅子は茶色である、これもパターンです。人間は、そのパターンの違いを瞬時に見分けるために、りんごを椅子と間違えないのです。しかし、コンピューターにとってりんごや椅子の画像からパターンを見つけ出すのはとても難しいです。「りんごは、赤色で半径5cm程度の球である。」とコンピューターに教えたところで、ボールを赤色に塗ったものをりんごと誤認してしまうのです。このように、人間の知識を特徴という記号だけで完全に記述するのは難しいです。(特徴を教えられただけで機械は本当に実物を「理解」出来るのかという問題は 「記号接地問題」 と呼ばれ、人工知能が解決すべき難解な問題の一つでした。)そのため、人間の知識を記述する以外の方法で、大量のりんごの写真から共通して現れるパターンを見つけ出し、取得する手法が必要になってきます。ひとくくりに手法といっても、様々なものが存在します。機械学習の手法を大きく3つに分けると、以下のようになります。教師あり学習(Supervised Learnings)教師なし学習(Unsupervised Learnings)強化学習(Reinforcement Learnings)ここで「教師」とは何のことを指すのでしょうか？次項から各手法についてみていきましょう。"

text3 = "さて、ここからは機械学習の中で、代表的な手法の一つ、 「教師あり学習」 について内容を学びましょう。教師あり学習の「教師」とは、「データに付随する正解ラベル」のことを言います。「データに付随する正解ラベル」とはどういうものを指すのでしょうか？以下の図を参照ください。さて、左から様々なデータと、その内容を表すカテゴリや数値が与えられています。こうした内容を表すデータは 「正解ラベル」 などと言われます。データ①は手書き文字(画像)で、教師データとして「５」が与えられています。データ②は写真のような画像で、教師データとして「horse」が与えられています。このように、画像データを扱うものは、「画像認識」などと言われており、機械学習のなかでもディープラーニングの得意とする分野です。 データ③は文章で、教師データとして「夏目漱石」が与えられています。このように、文章を扱うものは「自然言語処理」などと言われています。自然言語処理分野では、言語ごとに違うデータセットを用意しなければならないので、情報を集めにくいのが特徴でしょう。データ①〜③のように、最終的には カテゴリを予測するものを「分類問題」 と呼ばれます。 データ④は広さなどの定量的なデータなどをもとに、正解ラベルとして家賃「60,000円」が与えられています。最終的には家賃などの 数値を予測するものを「回帰問題」 と呼ばれます。以下に、教師あり学習の流れについてまとめておきます。様々な教師データをコンピューターに与え、「正解ラベル」を学習し、「正解ラベル」を出力するようにモデルを学習学習したモデルに未知のデータを適用した時に、「正解ラベル」に近い値が出るかどうか検証基本的には、大量のデータを使って、コンピュータが正解ラベルに近づくようにひたすら反復行うのが、教師あり学習の基本原理です。"

text4 = "さて、次に 「教師なし学習」 を確認しましょう。前節で確認したとおり、「教師あり学習」には「正解ラベル」という答えが存在するのに対し、 「教師なし学習」は「正解ラベル」がありません。 与えられたデータから規則性を発見し、学習する手法です。教師あり学習では、コンピューターにあらかじめ答えを与えていたのに対し、教師なし学習では、コンピューターに自分で導いてもらいます。そのため、教師なし学習には、正解や不正解が存在しないのが特徴です。上の20個の点の集合を見てください。人間がこの点の集合を見れば、3つのまとまりを帯びているのがすぐにわかると思います。この3つのまとまりを機械に認識させるには「教師なし学習」の一つである、 「クラスタリング」 といった手法を用います。すると、機械もこのように3つの塊で点が構成されているのを認識できるようになります。一般に、「教師なし学習」はデータの集合の中からある法則性やデータの塊を導き出すような意図で用いられます。 　教師なし学習はおすすめの商品やメニューを推薦するレコメンデーションで用いられたり、多次元のデータを人間が可視化しやすいように圧縮する時に用いられたり(主成分分析や次元削減などと呼ばれます)、情報を圧縮するために自然言語処理などの分野で頻出します。"

text5 = "さて、 「教師あり学習」「教師なし学習」の他に、最近注目されている手法として「強化学習」があります。ポイントは、「教師あり学習」がその名の通り、お手本となる教師を必要とするのに対し、「強化学習」は教師を必要としないということです。強化学習では、答えの代わりに「エージェント」と「環境」を与えます。エージェントと環境があって、エージェントが環境に対して行動をして、その結果として環境がエージェントに報酬を与え、与えられた報酬に基づいて、エージェントが行動に対して「良かった・悪かった」の評価をし、次の行動を決定する形になります。強化学習は、最近ではディープラーニングと組み合わせて用いられ、囲碁や将棋AIや、ロボットの操作制御などで用いられています。実際に強化学習のモデルとしては、こちらの動画が分かりやすいでしょう。0:16の時点では、学習が進んでおらず、ロボットがうまく円柱の部品をピッキングできていません。しかし、0:55の時点では、学習が進み、ロボットが9割以上の確率でうまく部品をピッキングできています。ロボットの動作やシミュレーションを通じ、コンピューターが自動的に「良い」評価になるような動き方を学習するのが「強化学習」です。"

text6 = "chapter1では、機械学習を大きく分けて３種類に大別されることを学びました。ここでは、機械学習を使えるようになるための一連の流れを確認しましょう。chapter2では、「教師あり学習」「教師なし学習」「強化学習」のなかで最も適応例が多い教師あり学習の一連の流れを追っていきます。教師あり学習で行うことの流れを以下にまとめます。データ収集データクレンジング（重複や欠損データなどを取り除いて、データの精度を高めること。）機械学習手法でデータを学習（基準の取得）テストデータで性能をテスト機械学習モデルをWEBなどに実装上記で機械学習が使われている部分は、3のみです。このように、 機械学習を行うといっても事前の準備や、結果の考察が必要 になってきます。大抵は、1と2にかなりの時間がかかります。例えば、画像認識分野では、用意する写真のデータだけで、数万枚もの写真データが必要なことがあります。データ量が多ければたとえコンピュータだとしてもデータの事前準備にかかる時間は増えますし、その結果を人間が確認し、再度１や２の処理にかけることもあります。機械学習を行う上では、地道な作業が必要になるのです。（データサイエンティストの仕事にかかる時間の8割以上は「データの収集やクレンジング」と言われています。）"

text7 = "本項では、前項で説明した機械学習の流れの内、「3.機械学習手法でデータを学習（基準の取得）」 の部分である機械学習について詳しく解説していきます。機械学習でよく使われるサンプルデータセットに 「Iris（あやめ）」 というものがあります。あやめは花の一種です。あやめの花びらを支える小さな葉のことを「がく片(sepal)」と呼び、花びらを「花弁(petal)」と呼びます。さらに、あやめには様々な品種が存在しますが、今回は 「setosa」「versicolor」という2つの品種を取り上げます。 ここでは、この品種を、「がく片(sepal)」と「花弁(petal)」の長さや幅で分類することを考えます。あらかじめ、あやめのsetosaとversicolorのがく片の長さとがく片の幅のデータが、それぞれ5個ずつ与えられているとします。グラフの横軸をがく片の長さ、縦軸をがく片の幅とした、散布図を見て見ましょう。すると、以下のようになります。赤の点がsetosaで青の点がversicolorになります。するとどうでしょうか。私たちの目から見ると、赤と青の点が以下のように一本の線で分けることができると思います。人間は簡単に、setosaかversicolorのどちらであるかを分類することができるかと思います。しかし、コンピュータにとってこのように分類することは容易ではありません。では、コンピュータはどのように分類できるようになるのでしょうか。以下に、コンピュータに分類をさせる流れをまとめます。まず適当な線を引かせる。その線が妥当な位置にあるかを、計算で求める。2での線の位置を改善する方に修正する。適切に点を分類できる位置に線を引けたら終了以上の流れで、機械が人間の目から見ても妥当な線を引くことが可能になります。あくまでも、上記の例は数多くある分類手法のうちの一つです。実際、2における計算についても多くの手法があります。それらについては教師あり学習(分類)コースで紹介をします。ここでは、コンピュータが自分で正しい線を引いているかどうかを計算し、修正しているといった認識で大丈夫です。 　2と3をひたすら反復することで、正しい線が描けるようになる のです。そして、4の時点で、コンピュータ自身は「このようなデータが来たら、このような線を引けば良いな。」と自分で学習したと言えます。このように、 コンピュータ自身が自分で答えを見つけ、データのパターンから作られた基準をモデル と言うのです。"

text8 = "次に、どのように機械学習の流れが進んでいくのか確認しましょう。 機械学習の「教師あり学習」では、 扱うデータを「トレーニングデータ」と「テストデータ」に分けて用います。 「トレーニングデータ」とは、学習に使うデータ、「テストデータ」とは、学習したモデルの精度評価に使われるデータです。「トレーニングデータ」と「テストデータ」に分ける理由は、 機械学習は「未知のデータを予測する」ことを目的とした学問体系 であるためです。機械学習は「画像に写っているものを認識したい」「株価を予測したい」「ニュース記事をカテゴリに分けたい」など様々な活用方法がありますが、すべて「未知のデータ」に対して学習済みモデルが適応されます。 そのため、機械学習のモデル評価には、学習には使われていないデータである「テストデータ」を用いるのです。（機械学習と似た学問に統計学がありますが、統計学の世界では「トレーニングデータ」と「テストデータ」に分けて使うことは稀です。これは、統計学では「データから現象を説明すること」に重きを置いているためです。）例えば、機械学習でよく用いられる「MNIST」という手書き文字認識によく使われるデータセットがあります。これは、全てのデータ（70,000枚の手書き文字画像）のうち、 60,000枚をトレーニングデータ、10,000枚をテストデータ として分けて使い、60,000枚のデータで学習モデルを作り、学習に使わなかった10,000枚のデータでその学習モデルも精度を検証することで知られています。ケースバイケースですが、多くの場合は全体のデータの20％ほどをテストデータに用いることが多いです。"

text9 = "さて、データを分ける方法として、今回は「ホールドアウト法」と「k-分割交差検証法」という手法を紹介します。まず 「ホールドアウト法」 についてです。ホールドアウト法とは、 与えられたデータセットをトレーニングデータとテストデータの二つに分割するシンプルな手法 です。 　今回はライブラリscikit-learnを使ったホールドアウト法の実践に関して確認します。scikit-learnはPythonのオープンソース機械学習ライブラリです。scikit-learnでホールドアウト法を実践するには、train_test_split関数を用います。用い方のサンプルは以下の通りです。Xにはデータセットの正解ラベルに対応する特徴が配列で並んでおり、yにはデータセットの正解ラベルが配列で並んでいるデータを用意したものとします。ここで、NUMには データ全体から、テストデータとして選びたい割合を0から1までの数値で指定 します。つまり、0.2を指定すると、データのうち20％がテストデータに、0.3を指定すると、データのうち30％がテストデータとして選ばれることになります。以上の指定を行うことによって、 以下のように格納されます。・X_train...トレーニングデータのデータセット（正解ラベル以外）・y_train...テストデータのデータセット（正解ラベル以外）・X_test...トレーニングデータの正解ラベル・y_test...テストデータの正解ラベルrandom_state=0は指定しなくても良い引数ですが、実験では指定する場合が多いです。random_state=0を指定しないと、テストに選ばれるデータセットが固定化せず、毎回ランダムに選ばれることになります。その場合、毎回データセットが変わるので、毎回精度が変わり、他者と精度を比較したり、実験の再現性を担保することができなくなってしまいます。そのため、この引数は指定する場合が多いです。train_test_split関数には他にも様々な引数がありますが、 重要なのはtest_size=XXXという引数 であることを覚えておきましょう。"

text10 = "k-分割交差検証（クロスバリデーション）とは、非復元抽出(一度抽出したデータをもとに戻すことのない抽出法)を用いて、 トレーニングデータセットをk分割し、そのうちのk-1個のデータを学習用のデータセットとして用い、残りの1個をモデルのテストに用いるといった手法 のことです。結果として、k個のモデルとそのモデルに対する性能評価がk個得られるため、 k回の学習と評価を繰り返し、そのk個の性能評価の平均をとり、平均性能を算出 します。 k-分割交差検証では、データセットからテストデータを抽出する全ての組み合わせを試せるため、より安定した正確なモデル評価ができると言えます。そのぶん、k回の学習と評価を行うので、ホールドアウト法よりもk倍の演算が必要というデメリットもあります。以下の図は、k=10の時のk-分割交差検証の様子を示しています。一般的に用いられるkの値は5-10程度です。データセットが大きい場合は、kの値を増やして分割数を増やすことで良い結果が得られる場合が多いです。なお、k分割交差検証には、 「一個抜き」(Leave-One-Out:LOO)交差検証 という特別な手法があります。k分割交差検証のうち、分割の個数をデータセットの数と同じにして、１行以外のデータセットで学習を行い、学習に使わなかった1行でモデルの精度評価を行う手法です(ここで、１行とは一つのデータを指します)。つまり、20行のデータがあったとしたら、19行で学習し、学習に使わなかった1行でテストを行う、という手法になり、合計20回の学習を行なったテスト結果の平均を取ることで精度を算出するのです。かなり小さいデータセット（例えばデータセットが50-100行以下）を扱う場合には、この手法が推奨されます。"

text11 = "さて、実際にコードを書いて「k-分割交差検証」の実践を行いましょう。サンプルは以下の通りです。Xにはデータセットの正解ラベル以外が配列で並んでおり、yにはデータセットの正解ラベルが配列で並んでいるデータを用意したものとします。以上を踏まえ、演習問題にチャレンジしましょう。なお、今回はまだ未習の機械学習モデル「SVM」が登場しています。このモデルの概要や引数の扱い方は「教師あり学習（分類）」で触れるので、今回は詳しく押さえられなくてもOKです。"

text12 = "データのパターンから基準を作り出したコンピュータに、さらに新しいデータを与えると、ひどいばらつきがない限りデータをパターンごとに分類できるようになります。では、コンピュータにトレーニングとして、偏りのあるデータを与えるとどうなるでしょうか。例えば、下図のようながく片の幅と長さによって、花の種類を分類しており、その一部が偏っているデータです。識別面が一つのデータに影響され、正しい線が引くことができていないのがわかります。このように、与えられたデータに適用し過ぎてしまい、正しい基準が構築されないことを、 コンピュータがデータを学習し過ぎた状態、過学習(オーバーフィッティング) と言います。"

text13 = "この過学習の解決手段はとして様々あります。例えば、ディープラーニングでは 「Dropout（ドロップアウト）」 という手法を用いることで過学習を防いでいます。これは、学習時にランダムに一部のニューロン（特定の入力に対し、値を出力するもの）を消し去る手法です。他にも、過学習を回避する方法の代表的なものの一つとして、正則化があります。正則化とは、簡単にいうと偏りがあるデータの影響をなくすことをさします。前項の過学習の場合に扱ったデータに正則化を適用すると、以下のようになります。データの集合から外れているデータの影響を正則化を用いることにより消しています。こうすることにより、データを学習しすぎることなく、データを分類することができます。なお、コンピュータがデータを学習しすぎる状態を、過学習と呼ぶのに対し、 データを学習できていない状態を学習不足 と呼びます。また、 過学習を起こしているモデルのことをバリアンスが高い と呼び、 学習不足を起こしているモデルのことをバイアスが高い と呼ぶことがあります。"

text14 = "アンサンブル学習は複数のモデルに学習させることによってデータの一般化を獲得しようとする試みです。ここでは紹介程度にとどめますが、主に2種類の手法が存在します。一つは バギング と呼ばれる手法であり、複数のモデルを同時に学習させ、予測結果の平均をとることで予測結果の汎化を試みます。もう一つは ブースティング と呼ばれる手法であり、モデルの予測結果に対するモデルを作成し汎化性能を高める手法です。"

text15 = "chapter3では、トレーニングデータを用いて構築された学習済みモデルが、 どの程度良いものであるかを判断する評価指標 について触れていきます。モデルの性能を評価する指標について詳しく紹介する前に、混同行列について紹介します。 混同行列とは、各テストデータに対するモデルの予測結果を、真陽性(True Positive)、真陰性(True Negative)、偽陽性(False Positive)、偽陰性(False Negative)の4つの観点で分類 をし、それぞれに当てはまる予測結果の個数をまとめた表です。「真か偽」は予測が的中したかどうか 、 「陽性か陰性」は予測されたクラス をそれぞれ示しています。つまり、 真陽性は陽性クラスと予測され結果も陽性クラスであった個数 真陰性は陰性クラスと予測され結果も陰性クラスであった個数 偽陽性は陽性クラスと予測されたが結果は陰性クラスであった個数 偽陰性は陰性クラスと予測されたが結果は陽性クラスであった個数 をそれぞれ示しています。真陽性(True Positive)と真陰性(True Negative)は機械学習モデルが正解し、偽陰性(False Negative)と偽陽性(False Positive)は機械学習モデルが不正解になったということを示しているのです。"

text16 = "前項では、混同行列の各要素について学習しました。この項では、sklearn.metricsモジュールにあるconfusion_matrix関数を利用して、実際に混同行列の各成分の個数を見てみましょう。confusion_matrix関数は、以下のように使うことができます。y_trueには、正解データの実際のクラスが配列で格納され、y_predには、予想されたクラスが配列で格納されます。格納のされ方は、前のセッションでも確認した下図の通りです。さて、実際に問題を解いて混合行列を実装しましょう。"

text17 = "実際に分類モデルを構築できたならば、その分類モデルは他の分類モデルより性能が優れているのか、優れていないのかを評価するための明確な基準といったものが必要になってきます。この項では、前の項で説明された混同行列の要素を元に算出できる 性能評価指標 について解説します。まずは「正解率」について確認します。 正解率とは、全ての事象の中で、診断結果が合っていた（TP/TNに分類された）数の割合 で、以下のように計算できます。とてもシンプルな指標なので、直感的に分かりやすいかもしれません。実際のケース問題で、正解率を計算してみましょう。"

text18 = "さて、他の例を考えてさらに理解を深めて行きます。ある病院の癌検診で患者10,000人を診療することを考えます。癌検診の結果、患者10,000人の診断結果の混合行列は以下のようになりました。直感的に、この診断の性能はあまり良くないように感じられませんでしょうか？100人の癌患者のうち、40％は「癌ではないだろう」と誤診をしてしまっていますし、陽性の患者が実際に癌である確率は、30％ほどだからです。しかし、正解率を計算すると、以下のようになります。正解率は98.2％という高い値 になりました。これは、 患者のほとんどが癌ではない ことによるものです。このように、 データに偏りがある状態で「正解率」という指標を使うのは非常に危険 です。そのため、 機械学習では適合率/精度(precision)、再現率(recall)、F値という指標で性能評価 されるケースが多いです。それぞれの評価指標に関して詳しく確認しましょう。まず、適合率/精度(precision)と再現率(recall)です。 適合率/精度(precision)とは陽性と予測されたデータのうち、実際に陽性であるものの割合 であり、 再現率(recall)は、実際の陽性のデータのうち、陽性と予測できたものの割合 を表しています。さらにF値とは 適合率と再現率の両方を組み合わせた（調和平均） です。F値は以下のように求めることはできます。適合率/精度(precision)、再現率(recall)、F値ともに、 0~1の範囲の中で示され、値が1に近いほうが「性能が良い」 ということを示しています。さて、実際に今回の癌検診のケースの適合率/精度(precision)、再現率(recall)、F値を求めてみましょう。実際計算してみるとprecision、recall、F値ともに大きい値（100％に近い値）とは言えません。なんとなく「直感」と合致した気がしますね。"

text19 = "前項では、モデルを評価する指標の計算式を学習しました。この項では、scikit-learnに実装されている性能評価指標を利用して見ましょう。その関数はsklearn.metricsモジュールからインポートできます。%.3fとは、Python入門のChapter3で学習した表現です。小数点4桁目で四捨五入され、小数点3桁で表示されることになります。"

text20 = "前項で様々な性能評価指標について学習いたしました。この項では、データから得られた再現率と適合率を用いてモデルの性能を評価する方法について学習していきます。復習になりますが、TP,FN,FP,TNの関係性と、再現率と適合率について再度確認しましょう。適合率 　陽性であると予測した内の何%が当たっていたかを示します。再現率 　本当に陽性であるケースの内、何%を陽性と判定できたかを示します。この 二つの性能評価指標の関係は、トレードオフの関係 になります。トレードオフの関係というのは、再現率を高くしようとすると適合率が低くなり、適合率を高くしようとすると再現率が低くなることを意味します。例えば、ある病院の癌検診の例を考えます。この病院が保守的な検査を行い、たくさんの陽性(癌である宣告)を出したと考えます。するとどうでしょうか。たくさん陽性を出しているので、本当に陽性である方の的中率が上がるので、これは再現率が高くなります。しかし、反対に少しでも癌の兆候が見られればすぐ陽性と判断してしまっているので、適合率が下がります。今度は、たくさんの陰性(癌ではない宣告)を出したと考えます。すると、一般的には、陰性の患者数の方が多いため、たくさんの陰性判断をすることで適合率が上がります。逆に、再現率は低くなってしまいます。このように、片方を上げようとすると片方が下がってしまうのです。今回のような 癌検診のケースだと、Recallを重視 するのが良いでしょう。というのも 「癌の発見を見逃す」というケースは人の命に関わる重大なケース であり、できるだけFNの数を少なくすることが必要であるためです。逆に、例えば WEBサービスのレコメンドなどだとPrecisionを重視 するのが良いでしょう。例えば、「自分の好みでない商品をレコメンド」してしまうと、サービスの信頼性・ブランド力が毀損してしまうためです。つまり、 「自分の好みの商品をレコメンドできない（=購買機会の減少）」ことよりも、「自分の好みでない商品をレコメンドしてしまう（=信頼性の減少）」ことを避けたいケース だと、できるだけFPの数を少なくすることが必要であるためです。以上のようなこだわりが特にないケースだと、 再現率と適合率の両方を考慮したF値 が用いられます。"

text21 = "PR曲線とは、横軸を再現率、縦軸を適合率として、データをプロットしたグラフを表したものです。例を挙げます。癌検診を受けた10人の患者に対し、それぞれについて癌である可能性を算出したうえで、それをもとに患者に陽性か陰性か宣告することを考えます。この場合、適合率は、癌検診で陽性と宣告された患者数の内、本当に癌である患者の割合であり、再現率は、本当に癌である患者のうち、癌と宣告された割合です。ここで問題となってくるのは、患者10人を癌の可能性が高い順に並べたとき、上位何番目の人まで陽性と宣告するかです。この何番目の人まで陽性と宣告するかによって、再現率・適合率はともに変わってきます。 　このとき、1番の人だけを陽性とした場合、2番の人までを陽性とした場合、……と順に適合率と再現率を計算し、それらをすべてプロットした図がPR曲線と言えます。プロットされる過程は以下のようになります。これらの適合率、再現率をプロットすると以下のようになります。上図より、やはり再現率と適合率の関係はトレードオフであると言えます。さて、PR曲線の仕組みがわかったところで、PR曲線を用いたモデルの評価について次項で説明していきます。"

text22 = "まず、適合率と再現率について別の見方をしてみましょう。前項の癌検診における例を、ビジネスにおける、全顧客の中から優先してアプローチすべき優良顧客を判定する問題に置き換えます。優良顧客であると予想した顧客と、本当の優良顧客に分かれます。つまり以下のようになります。適合率(Precision)が高く、再現率(Recall)が低い状態 無駄は少ないが，取りこぼしの多い判定になっている状態と言えます。つまり機会損失が生じていると言えます。適合率(Precision)が低く、再現率(Recall)が高い状態 取りこぼしが少ないが，無駄撃ちが多い判定になっている状態と言えます。つまりアプローチの予算が無駄になる可能性が高いと言えます。適合率も再現率も高いに越したことはありません。ですが、 トレードオフの関係のため、どちらかを上げようとするとどちらかが下がってしまいます。 しかし、PR曲線には適合率と再現率が一致する点が存在します。この点を、 ブレークイーブンポイント(BEP) と呼びます。この点では、適合率と再現率の関係をバランスよく保ったまま、コストと利益を最適化できるので、ビジネスにおいては重要な点となっております。前々節で F値 という評価指標に触れましたが、ブレークイーブンポイントも同じような概念と押さえておけばよいでしょう。さて、PR曲線がかけたところで、PR曲線を用いたモデルの評価をしてみましょう。PR曲線によるモデルの優劣は以下のようになります。つまり、BEPが右上に遷移するほど良いモデルが構築できたと言えます。これは、BEPが右上に遷移するほど、適合率と再現率が同時に高くなるためです。"

text = text1 + text2 + text3 + text4 + text5 + text6 + text7 + text8 + text9 + text10 + text11 + text12 + text13 + text14 + text15 + text16 + text17 + text18 + text19 + text20 + text21 + text22  

t = Tokenizer()
tokens = t.tokenize(text)
word=[]

for token in tokens:
	part_of_speech = token.part_of_speech.split(",")[0]

	if part_of_speech == "名詞":
	    word.append(token.surface)        
	if part_of_speech == "動詞":        
	    word.append(token.surface)
	if part_of_speech == "形容詞":
	    word.append(token.surface)        
	if part_of_speech == "形容動詞":        
	    word.append(token.surface)            

documents = [word]
# corporaを使い単語辞書を作成してください。
dictionary = corpora.Dictionary(documents)
print(dictionary)
# 各単語のidを表示してください
print(dictionary.token2id)

# Bag of Wordsの作成してください
bow_corpus = [dictionary.doc2bow(d) for d in documents]

# (id, 出現回数)のリストが出力されます。
print(bow_corpus)

print()
# bow_corpusの内容をわかりやすく出力する
texts = [text]
for i in range(len(bow_corpus)):
    print(texts[i])
    for j in range(len(bow_corpus[i])):
        index = bow_corpus[i][j][0]
        num = bow_corpus[i][j][1]
        print("\"", dictionary[index], "\" が " ,num, "回", end="\n ")
    print()
