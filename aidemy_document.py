text1 = "機械学習はそもそもなぜ大きく注目されるのでしょうか。主な理由の一つとして、「 人間では到底実現不可能な時間で、大量のデータから自動的に短時間で正確な結果を得ることができる。 」ことが挙げられます。機械学習は、大量のデータからパターンを読み取り、問題を解決します。大量のデータを人力で解決するとなると、非常にコストがかかり現実的ではありません。以上の理由から、画像、音声、マーケティング、自然言語、医療など様々な分野において真価を発揮し、今日機械学習が大変注目を集めています。さらに、時代とともに、コンピュータの処理速度が向上し豊富なデータの解析に耐えうるデバイスが登場したのもその要因の一つでしょう。さて、最近「人工知能(AI)」「機械学習(マシンラーニング)」「深層学習(ディープラーニング)」など、様々な技術が挙げられています。こうした概念の関係性を以下の図に示します。上記の図からも分かるように、人工知能(AI)はかなり広範囲の言葉です。例えば、ひたすら条件を並べて分類するようなアルゴリズムも人工知能と言われます。(If-Then形式の知識表現アルゴリズムなどと呼ばれることもあります。)こうした手法は、昨今話題の技術とは言いにくいので、Aidemyでは取り扱いません。ここからは、「深層学習を含む機械学習(ディープラーニング)」を概観していきましょう。"

text2 = "そもそも機械学習の言葉の意味はなんでしょうか。簡単に言うと、機械学習とは「 データから反復的に学習し、そこに潜むパターンを探し出すこと。 」と言えます。データに潜むパターンとはなんでしょうか。少し、考えてみましょう。人間は、目の中にある網膜から光の信号を受け取り、瞳に何が写っているか高速に認識することができます。りんごやみかんといった果物や、机や椅子といった家具を瞬時に見分けることができ、りんごを椅子と間違うことはありません。なぜ、間違えないのでしょうか。それは、りんごと椅子との間に特徴(パターン)の違いがあるからです。りんごと椅子、それぞれにあるパターンが存在します。椅子は四角でりんごは丸い、これも一つのパターンです。りんごは赤色で、椅子は茶色である、これもパターンです。人間は、そのパターンの違いを瞬時に見分けるために、りんごを椅子と間違えないのです。しかし、コンピューターにとってりんごや椅子の画像からパターンを見つけ出すのはとても難しいです。「りんごは、赤色で半径5cm程度の球である。」とコンピューターに教えたところで、ボールを赤色に塗ったものをりんごと誤認してしまうのです。このように、人間の知識を特徴という記号だけで完全に記述するのは難しいです。(特徴を教えられただけで機械は本当に実物を「理解」出来るのかという問題は 「記号接地問題」 と呼ばれ、人工知能が解決すべき難解な問題の一つでした。)そのため、人間の知識を記述する以外の方法で、大量のりんごの写真から共通して現れるパターンを見つけ出し、取得する手法が必要になってきます。ひとくくりに手法といっても、様々なものが存在します。機械学習の手法を大きく3つに分けると、以下のようになります。教師あり学習(Supervised Learnings)教師なし学習(Unsupervised Learnings)強化学習(Reinforcement Learnings)ここで「教師」とは何のことを指すのでしょうか？次項から各手法についてみていきましょう。"

text3 = "さて、ここからは機械学習の中で、代表的な手法の一つ、 「教師あり学習」 について内容を学びましょう。教師あり学習の「教師」とは、「データに付随する正解ラベル」のことを言います。「データに付随する正解ラベル」とはどういうものを指すのでしょうか？以下の図を参照ください。さて、左から様々なデータと、その内容を表すカテゴリや数値が与えられています。こうした内容を表すデータは 「正解ラベル」 などと言われます。データ①は手書き文字(画像)で、教師データとして「５」が与えられています。データ②は写真のような画像で、教師データとして「horse」が与えられています。このように、画像データを扱うものは、「画像認識」などと言われており、機械学習のなかでもディープラーニングの得意とする分野です。 データ③は文章で、教師データとして「夏目漱石」が与えられています。このように、文章を扱うものは「自然言語処理」などと言われています。自然言語処理分野では、言語ごとに違うデータセットを用意しなければならないので、情報を集めにくいのが特徴でしょう。データ①〜③のように、最終的には カテゴリを予測するものを「分類問題」 と呼ばれます。 データ④は広さなどの定量的なデータなどをもとに、正解ラベルとして家賃「60,000円」が与えられています。最終的には家賃などの 数値を予測するものを「回帰問題」 と呼ばれます。以下に、教師あり学習の流れについてまとめておきます。様々な教師データをコンピューターに与え、「正解ラベル」を学習し、「正解ラベル」を出力するようにモデルを学習学習したモデルに未知のデータを適用した時に、「正解ラベル」に近い値が出るかどうか検証基本的には、大量のデータを使って、コンピュータが正解ラベルに近づくようにひたすら反復行うのが、教師あり学習の基本原理です。"

text4 = "さて、次に 「教師なし学習」 を確認しましょう。前節で確認したとおり、「教師あり学習」には「正解ラベル」という答えが存在するのに対し、 「教師なし学習」は「正解ラベル」がありません。 与えられたデータから規則性を発見し、学習する手法です。教師あり学習では、コンピューターにあらかじめ答えを与えていたのに対し、教師なし学習では、コンピューターに自分で導いてもらいます。そのため、教師なし学習には、正解や不正解が存在しないのが特徴です。上の20個の点の集合を見てください。人間がこの点の集合を見れば、3つのまとまりを帯びているのがすぐにわかると思います。この3つのまとまりを機械に認識させるには「教師なし学習」の一つである、 「クラスタリング」 といった手法を用います。すると、機械もこのように3つの塊で点が構成されているのを認識できるようになります。一般に、「教師なし学習」はデータの集合の中からある法則性やデータの塊を導き出すような意図で用いられます。 　教師なし学習はおすすめの商品やメニューを推薦するレコメンデーションで用いられたり、多次元のデータを人間が可視化しやすいように圧縮する時に用いられたり(主成分分析や次元削減などと呼ばれます)、情報を圧縮するために自然言語処理などの分野で頻出します。"

text5 = "さて、 「教師あり学習」「教師なし学習」の他に、最近注目されている手法として「強化学習」があります。ポイントは、「教師あり学習」がその名の通り、お手本となる教師を必要とするのに対し、「強化学習」は教師を必要としないということです。強化学習では、答えの代わりに「エージェント」と「環境」を与えます。エージェントと環境があって、エージェントが環境に対して行動をして、その結果として環境がエージェントに報酬を与え、与えられた報酬に基づいて、エージェントが行動に対して「良かった・悪かった」の評価をし、次の行動を決定する形になります。強化学習は、最近ではディープラーニングと組み合わせて用いられ、囲碁や将棋AIや、ロボットの操作制御などで用いられています。実際に強化学習のモデルとしては、こちらの動画が分かりやすいでしょう。0:16の時点では、学習が進んでおらず、ロボットがうまく円柱の部品をピッキングできていません。しかし、0:55の時点では、学習が進み、ロボットが9割以上の確率でうまく部品をピッキングできています。ロボットの動作やシミュレーションを通じ、コンピューターが自動的に「良い」評価になるような動き方を学習するのが「強化学習」です。"

text6 = "chapter1では、機械学習を大きく分けて３種類に大別されることを学びました。ここでは、機械学習を使えるようになるための一連の流れを確認しましょう。chapter2では、「教師あり学習」「教師なし学習」「強化学習」のなかで最も適応例が多い教師あり学習の一連の流れを追っていきます。教師あり学習で行うことの流れを以下にまとめます。データ収集データクレンジング（重複や欠損データなどを取り除いて、データの精度を高めること。）機械学習手法でデータを学習（基準の取得）テストデータで性能をテスト機械学習モデルをWEBなどに実装上記で機械学習が使われている部分は、3のみです。このように、 機械学習を行うといっても事前の準備や、結果の考察が必要 になってきます。大抵は、1と2にかなりの時間がかかります。例えば、画像認識分野では、用意する写真のデータだけで、数万枚もの写真データが必要なことがあります。データ量が多ければたとえコンピュータだとしてもデータの事前準備にかかる時間は増えますし、その結果を人間が確認し、再度１や２の処理にかけることもあります。機械学習を行う上では、地道な作業が必要になるのです。（データサイエンティストの仕事にかかる時間の8割以上は「データの収集やクレンジング」と言われています。）"

text7 = "本項では、前項で説明した機械学習の流れの内、「3.機械学習手法でデータを学習（基準の取得）」 の部分である機械学習について詳しく解説していきます。機械学習でよく使われるサンプルデータセットに 「Iris（あやめ）」 というものがあります。あやめは花の一種です。あやめの花びらを支える小さな葉のことを「がく片(sepal)」と呼び、花びらを「花弁(petal)」と呼びます。さらに、あやめには様々な品種が存在しますが、今回は 「setosa」「versicolor」という2つの品種を取り上げます。 ここでは、この品種を、「がく片(sepal)」と「花弁(petal)」の長さや幅で分類することを考えます。あらかじめ、あやめのsetosaとversicolorのがく片の長さとがく片の幅のデータが、それぞれ5個ずつ与えられているとします。グラフの横軸をがく片の長さ、縦軸をがく片の幅とした、散布図を見て見ましょう。すると、以下のようになります。赤の点がsetosaで青の点がversicolorになります。するとどうでしょうか。私たちの目から見ると、赤と青の点が以下のように一本の線で分けることができると思います。人間は簡単に、setosaかversicolorのどちらであるかを分類することができるかと思います。しかし、コンピュータにとってこのように分類することは容易ではありません。では、コンピュータはどのように分類できるようになるのでしょうか。以下に、コンピュータに分類をさせる流れをまとめます。まず適当な線を引かせる。その線が妥当な位置にあるかを、計算で求める。2での線の位置を改善する方に修正する。適切に点を分類できる位置に線を引けたら終了以上の流れで、機械が人間の目から見ても妥当な線を引くことが可能になります。あくまでも、上記の例は数多くある分類手法のうちの一つです。実際、2における計算についても多くの手法があります。それらについては教師あり学習(分類)コースで紹介をします。ここでは、コンピュータが自分で正しい線を引いているかどうかを計算し、修正しているといった認識で大丈夫です。 　2と3をひたすら反復することで、正しい線が描けるようになる のです。そして、4の時点で、コンピュータ自身は「このようなデータが来たら、このような線を引けば良いな。」と自分で学習したと言えます。このように、 コンピュータ自身が自分で答えを見つけ、データのパターンから作られた基準をモデル と言うのです。"

text8 = "次に、どのように機械学習の流れが進んでいくのか確認しましょう。 機械学習の「教師あり学習」では、 扱うデータを「トレーニングデータ」と「テストデータ」に分けて用います。 「トレーニングデータ」とは、学習に使うデータ、「テストデータ」とは、学習したモデルの精度評価に使われるデータです。「トレーニングデータ」と「テストデータ」に分ける理由は、 機械学習は「未知のデータを予測する」ことを目的とした学問体系 であるためです。機械学習は「画像に写っているものを認識したい」「株価を予測したい」「ニュース記事をカテゴリに分けたい」など様々な活用方法がありますが、すべて「未知のデータ」に対して学習済みモデルが適応されます。 そのため、機械学習のモデル評価には、学習には使われていないデータである「テストデータ」を用いるのです。（機械学習と似た学問に統計学がありますが、統計学の世界では「トレーニングデータ」と「テストデータ」に分けて使うことは稀です。これは、統計学では「データから現象を説明すること」に重きを置いているためです。）例えば、機械学習でよく用いられる「MNIST」という手書き文字認識によく使われるデータセットがあります。これは、全てのデータ（70,000枚の手書き文字画像）のうち、 60,000枚をトレーニングデータ、10,000枚をテストデータ として分けて使い、60,000枚のデータで学習モデルを作り、学習に使わなかった10,000枚のデータでその学習モデルも精度を検証することで知られています。ケースバイケースですが、多くの場合は全体のデータの20％ほどをテストデータに用いることが多いです。"

text9 = "さて、データを分ける方法として、今回は「ホールドアウト法」と「k-分割交差検証法」という手法を紹介します。まず 「ホールドアウト法」 についてです。ホールドアウト法とは、 与えられたデータセットをトレーニングデータとテストデータの二つに分割するシンプルな手法 です。 　今回はライブラリscikit-learnを使ったホールドアウト法の実践に関して確認します。scikit-learnはPythonのオープンソース機械学習ライブラリです。scikit-learnでホールドアウト法を実践するには、train_test_split関数を用います。用い方のサンプルは以下の通りです。Xにはデータセットの正解ラベルに対応する特徴が配列で並んでおり、yにはデータセットの正解ラベルが配列で並んでいるデータを用意したものとします。ここで、NUMには データ全体から、テストデータとして選びたい割合を0から1までの数値で指定 します。つまり、0.2を指定すると、データのうち20％がテストデータに、0.3を指定すると、データのうち30％がテストデータとして選ばれることになります。以上の指定を行うことによって、 以下のように格納されます。・X_train...トレーニングデータのデータセット（正解ラベル以外）・y_train...テストデータのデータセット（正解ラベル以外）・X_test...トレーニングデータの正解ラベル・y_test...テストデータの正解ラベルrandom_state=0は指定しなくても良い引数ですが、実験では指定する場合が多いです。random_state=0を指定しないと、テストに選ばれるデータセットが固定化せず、毎回ランダムに選ばれることになります。その場合、毎回データセットが変わるので、毎回精度が変わり、他者と精度を比較したり、実験の再現性を担保することができなくなってしまいます。そのため、この引数は指定する場合が多いです。train_test_split関数には他にも様々な引数がありますが、 重要なのはtest_size=XXXという引数 であることを覚えておきましょう。"

text10 = "k-分割交差検証（クロスバリデーション）とは、非復元抽出(一度抽出したデータをもとに戻すことのない抽出法)を用いて、 トレーニングデータセットをk分割し、そのうちのk-1個のデータを学習用のデータセットとして用い、残りの1個をモデルのテストに用いるといった手法 のことです。結果として、k個のモデルとそのモデルに対する性能評価がk個得られるため、 k回の学習と評価を繰り返し、そのk個の性能評価の平均をとり、平均性能を算出 します。 k-分割交差検証では、データセットからテストデータを抽出する全ての組み合わせを試せるため、より安定した正確なモデル評価ができると言えます。そのぶん、k回の学習と評価を行うので、ホールドアウト法よりもk倍の演算が必要というデメリットもあります。以下の図は、k=10の時のk-分割交差検証の様子を示しています。一般的に用いられるkの値は5-10程度です。データセットが大きい場合は、kの値を増やして分割数を増やすことで良い結果が得られる場合が多いです。なお、k分割交差検証には、 「一個抜き」(Leave-One-Out:LOO)交差検証 という特別な手法があります。k分割交差検証のうち、分割の個数をデータセットの数と同じにして、１行以外のデータセットで学習を行い、学習に使わなかった1行でモデルの精度評価を行う手法です(ここで、１行とは一つのデータを指します)。つまり、20行のデータがあったとしたら、19行で学習し、学習に使わなかった1行でテストを行う、という手法になり、合計20回の学習を行なったテスト結果の平均を取ることで精度を算出するのです。かなり小さいデータセット（例えばデータセットが50-100行以下）を扱う場合には、この手法が推奨されます。"

text11 = "さて、実際にコードを書いて「k-分割交差検証」の実践を行いましょう。サンプルは以下の通りです。Xにはデータセットの正解ラベル以外が配列で並んでおり、yにはデータセットの正解ラベルが配列で並んでいるデータを用意したものとします。以上を踏まえ、演習問題にチャレンジしましょう。なお、今回はまだ未習の機械学習モデル「SVM」が登場しています。このモデルの概要や引数の扱い方は「教師あり学習（分類）」で触れるので、今回は詳しく押さえられなくてもOKです。"

text12 = "データのパターンから基準を作り出したコンピュータに、さらに新しいデータを与えると、ひどいばらつきがない限りデータをパターンごとに分類できるようになります。では、コンピュータにトレーニングとして、偏りのあるデータを与えるとどうなるでしょうか。例えば、下図のようながく片の幅と長さによって、花の種類を分類しており、その一部が偏っているデータです。識別面が一つのデータに影響され、正しい線が引くことができていないのがわかります。このように、与えられたデータに適用し過ぎてしまい、正しい基準が構築されないことを、 コンピュータがデータを学習し過ぎた状態、過学習(オーバーフィッティング) と言います。"

text13 = "この過学習の解決手段はとして様々あります。例えば、ディープラーニングでは 「Dropout（ドロップアウト）」 という手法を用いることで過学習を防いでいます。これは、学習時にランダムに一部のニューロン（特定の入力に対し、値を出力するもの）を消し去る手法です。他にも、過学習を回避する方法の代表的なものの一つとして、正則化があります。正則化とは、簡単にいうと偏りがあるデータの影響をなくすことをさします。前項の過学習の場合に扱ったデータに正則化を適用すると、以下のようになります。データの集合から外れているデータの影響を正則化を用いることにより消しています。こうすることにより、データを学習しすぎることなく、データを分類することができます。なお、コンピュータがデータを学習しすぎる状態を、過学習と呼ぶのに対し、 データを学習できていない状態を学習不足 と呼びます。また、 過学習を起こしているモデルのことをバリアンスが高い と呼び、 学習不足を起こしているモデルのことをバイアスが高い と呼ぶことがあります。"

text14 = "アンサンブル学習は複数のモデルに学習させることによってデータの一般化を獲得しようとする試みです。ここでは紹介程度にとどめますが、主に2種類の手法が存在します。一つは バギング と呼ばれる手法であり、複数のモデルを同時に学習させ、予測結果の平均をとることで予測結果の汎化を試みます。もう一つは ブースティング と呼ばれる手法であり、モデルの予測結果に対するモデルを作成し汎化性能を高める手法です。"

text15 = "chapter3では、トレーニングデータを用いて構築された学習済みモデルが、 どの程度良いものであるかを判断する評価指標 について触れていきます。モデルの性能を評価する指標について詳しく紹介する前に、混同行列について紹介します。 混同行列とは、各テストデータに対するモデルの予測結果を、真陽性(True Positive)、真陰性(True Negative)、偽陽性(False Positive)、偽陰性(False Negative)の4つの観点で分類 をし、それぞれに当てはまる予測結果の個数をまとめた表です。「真か偽」は予測が的中したかどうか 、 「陽性か陰性」は予測されたクラス をそれぞれ示しています。つまり、 真陽性は陽性クラスと予測され結果も陽性クラスであった個数 真陰性は陰性クラスと予測され結果も陰性クラスであった個数 偽陽性は陽性クラスと予測されたが結果は陰性クラスであった個数 偽陰性は陰性クラスと予測されたが結果は陽性クラスであった個数 をそれぞれ示しています。真陽性(True Positive)と真陰性(True Negative)は機械学習モデルが正解し、偽陰性(False Negative)と偽陽性(False Positive)は機械学習モデルが不正解になったということを示しているのです。"

text16 = "前項では、混同行列の各要素について学習しました。この項では、sklearn.metricsモジュールにあるconfusion_matrix関数を利用して、実際に混同行列の各成分の個数を見てみましょう。confusion_matrix関数は、以下のように使うことができます。y_trueには、正解データの実際のクラスが配列で格納され、y_predには、予想されたクラスが配列で格納されます。格納のされ方は、前のセッションでも確認した下図の通りです。さて、実際に問題を解いて混合行列を実装しましょう。"

text17 = "実際に分類モデルを構築できたならば、その分類モデルは他の分類モデルより性能が優れているのか、優れていないのかを評価するための明確な基準といったものが必要になってきます。この項では、前の項で説明された混同行列の要素を元に算出できる 性能評価指標 について解説します。まずは「正解率」について確認します。 正解率とは、全ての事象の中で、診断結果が合っていた（TP/TNに分類された）数の割合 で、以下のように計算できます。とてもシンプルな指標なので、直感的に分かりやすいかもしれません。実際のケース問題で、正解率を計算してみましょう。"

text18 = "さて、他の例を考えてさらに理解を深めて行きます。ある病院の癌検診で患者10,000人を診療することを考えます。癌検診の結果、患者10,000人の診断結果の混合行列は以下のようになりました。直感的に、この診断の性能はあまり良くないように感じられませんでしょうか？100人の癌患者のうち、40％は「癌ではないだろう」と誤診をしてしまっていますし、陽性の患者が実際に癌である確率は、30％ほどだからです。しかし、正解率を計算すると、以下のようになります。正解率は98.2％という高い値 になりました。これは、 患者のほとんどが癌ではない ことによるものです。このように、 データに偏りがある状態で「正解率」という指標を使うのは非常に危険 です。そのため、 機械学習では適合率/精度(precision)、再現率(recall)、F値という指標で性能評価 されるケースが多いです。それぞれの評価指標に関して詳しく確認しましょう。まず、適合率/精度(precision)と再現率(recall)です。 適合率/精度(precision)とは陽性と予測されたデータのうち、実際に陽性であるものの割合 であり、 再現率(recall)は、実際の陽性のデータのうち、陽性と予測できたものの割合 を表しています。さらにF値とは 適合率と再現率の両方を組み合わせた（調和平均） です。F値は以下のように求めることはできます。適合率/精度(precision)、再現率(recall)、F値ともに、 0~1の範囲の中で示され、値が1に近いほうが「性能が良い」 ということを示しています。さて、実際に今回の癌検診のケースの適合率/精度(precision)、再現率(recall)、F値を求めてみましょう。実際計算してみるとprecision、recall、F値ともに大きい値（100％に近い値）とは言えません。なんとなく「直感」と合致した気がしますね。"

text19 = "前項では、モデルを評価する指標の計算式を学習しました。この項では、scikit-learnに実装されている性能評価指標を利用して見ましょう。その関数はsklearn.metricsモジュールからインポートできます。%.3fとは、Python入門のChapter3で学習した表現です。小数点4桁目で四捨五入され、小数点3桁で表示されることになります。"

text20 = "前項で様々な性能評価指標について学習いたしました。この項では、データから得られた再現率と適合率を用いてモデルの性能を評価する方法について学習していきます。復習になりますが、TP,FN,FP,TNの関係性と、再現率と適合率について再度確認しましょう。適合率 　陽性であると予測した内の何%が当たっていたかを示します。再現率 　本当に陽性であるケースの内、何%を陽性と判定できたかを示します。この 二つの性能評価指標の関係は、トレードオフの関係 になります。トレードオフの関係というのは、再現率を高くしようとすると適合率が低くなり、適合率を高くしようとすると再現率が低くなることを意味します。例えば、ある病院の癌検診の例を考えます。この病院が保守的な検査を行い、たくさんの陽性(癌である宣告)を出したと考えます。するとどうでしょうか。たくさん陽性を出しているので、本当に陽性である方の的中率が上がるので、これは再現率が高くなります。しかし、反対に少しでも癌の兆候が見られればすぐ陽性と判断してしまっているので、適合率が下がります。今度は、たくさんの陰性(癌ではない宣告)を出したと考えます。すると、一般的には、陰性の患者数の方が多いため、たくさんの陰性判断をすることで適合率が上がります。逆に、再現率は低くなってしまいます。このように、片方を上げようとすると片方が下がってしまうのです。今回のような 癌検診のケースだと、Recallを重視 するのが良いでしょう。というのも 「癌の発見を見逃す」というケースは人の命に関わる重大なケース であり、できるだけFNの数を少なくすることが必要であるためです。逆に、例えば WEBサービスのレコメンドなどだとPrecisionを重視 するのが良いでしょう。例えば、「自分の好みでない商品をレコメンド」してしまうと、サービスの信頼性・ブランド力が毀損してしまうためです。つまり、 「自分の好みの商品をレコメンドできない（=購買機会の減少）」ことよりも、「自分の好みでない商品をレコメンドしてしまう（=信頼性の減少）」ことを避けたいケース だと、できるだけFPの数を少なくすることが必要であるためです。以上のようなこだわりが特にないケースだと、 再現率と適合率の両方を考慮したF値 が用いられます。"

text21 = "PR曲線とは、横軸を再現率、縦軸を適合率として、データをプロットしたグラフを表したものです。例を挙げます。癌検診を受けた10人の患者に対し、それぞれについて癌である可能性を算出したうえで、それをもとに患者に陽性か陰性か宣告することを考えます。この場合、適合率は、癌検診で陽性と宣告された患者数の内、本当に癌である患者の割合であり、再現率は、本当に癌である患者のうち、癌と宣告された割合です。ここで問題となってくるのは、患者10人を癌の可能性が高い順に並べたとき、上位何番目の人まで陽性と宣告するかです。この何番目の人まで陽性と宣告するかによって、再現率・適合率はともに変わってきます。 　このとき、1番の人だけを陽性とした場合、2番の人までを陽性とした場合、……と順に適合率と再現率を計算し、それらをすべてプロットした図がPR曲線と言えます。プロットされる過程は以下のようになります。これらの適合率、再現率をプロットすると以下のようになります。上図より、やはり再現率と適合率の関係はトレードオフであると言えます。さて、PR曲線の仕組みがわかったところで、PR曲線を用いたモデルの評価について次項で説明していきます。"

text22 = "まず、適合率と再現率について別の見方をしてみましょう。前項の癌検診における例を、ビジネスにおける、全顧客の中から優先してアプローチすべき優良顧客を判定する問題に置き換えます。優良顧客であると予想した顧客と、本当の優良顧客に分かれます。つまり以下のようになります。適合率(Precision)が高く、再現率(Recall)が低い状態 無駄は少ないが，取りこぼしの多い判定になっている状態と言えます。つまり機会損失が生じていると言えます。適合率(Precision)が低く、再現率(Recall)が高い状態 取りこぼしが少ないが，無駄撃ちが多い判定になっている状態と言えます。つまりアプローチの予算が無駄になる可能性が高いと言えます。適合率も再現率も高いに越したことはありません。ですが、 トレードオフの関係のため、どちらかを上げようとするとどちらかが下がってしまいます。 しかし、PR曲線には適合率と再現率が一致する点が存在します。この点を、 ブレークイーブンポイント(BEP) と呼びます。この点では、適合率と再現率の関係をバランスよく保ったまま、コストと利益を最適化できるので、ビジネスにおいては重要な点となっております。前々節で F値 という評価指標に触れましたが、ブレークイーブンポイントも同じような概念と押さえておけばよいでしょう。さて、PR曲線がかけたところで、PR曲線を用いたモデルの評価をしてみましょう。PR曲線によるモデルの優劣は以下のようになります。つまり、BEPが右上に遷移するほど良いモデルが構築できたと言えます。これは、BEPが右上に遷移するほど、適合率と再現率が同時に高くなるためです。"

text23 = "それではこの講座のゴール地点を先に体験してみましょう。この講座を最後まで受講すると 問題のような、手書き数字画像データから数字を判別できるコードを書けるようになります。今回の講座では、ディープラーニングのなかでも最も基本的なアルゴリズムである、 ディープニューラルネットワーク を扱います。また、ライブラリは Keras + Tensorflow を利用しています。 Tensorflow とは、Google社製のディープラーニング用ライブラリであり、最も人気のあるディープラーニングライブラリの一つです。 Keras とは、 Tensorflowを扱いやすくするためのライブラリで、「ラッパー」と呼ばれています。コードの各内容についてはこの後のセッションで詳しく説明していきます。"

text24 = "深層学習 とは、動物の神経ネットワークを参考にした ディープニューラルネットワーク というモデルを使い、データの分類や回帰を行う手法です。 また 深層学習は機械学習の1手法である ことに注意しましょう。ディープニューラルネットワークの発想の起点は神経ネットワークにありますが、脳の神経ネットワークを再現する、ということは目標にしておらず、現在は純粋に精度を高めるような研究が盛んにされています。なぜここまで深層学習が注目されているかと言われれば、従来手法において人手がかかる作業が自動化され、かつ精度が高いからです。例えば、車の検出をするタスクを考えます。従来手法では、まず人間が車の検出に重要そうな特徴部分(タイヤやフロントガラスなど)をあらかじめ決めて、それを重点的に捉えられるようなモデルを考えます。しかし深層学習はそのような特徴を 自動 で見つけてしまいます。"

text25 = "近年、盛んに耳にするニューラルネットワークですが、発想自体は1950年代から存在しました。下の図がニューラルネットワークの基本となるニューロンです。が入力でが重みパラメータです。の値がある閾値よりも高ければこのニューロンは発火して1を出力し、そうでなければ0を出力する、というモデルです。このニューロンですが、これだけではあまり複雑な問題を解くことができませんでした。しかし下図のように層を積み重ねることで複雑な問題を扱えるようになりました。 これが ディープニューラルネットワーク です。ディープと言われる所以は層が積み重なっており、深い構造をしているためです。近年急激にディープニューラルネットワークが注目された理由は、層が深くてもうまく学習できるような手法が発見され、かつ学習できるような計算環境が整ったからです。ニューラルネットワークは、入力X（ベクトルや行列など）を受け取ると連鎖的に反応を起こし、最終的にある値y（スカラーやベクトルなど）を出力します。 例えば画像認識では、画像のピクセルのデータを入力することで、カテゴリ(ネコ、イヌ、ライオン...)に属する確率が得られます。深層学習では、 各ニューロンの重みパラメータを機械的に調整する ことで分類モデルや回帰モデルを作ります。"

text26 = "ネットワークモデルを作るいくつかのニューロンを束ねた層を図のように重ねていくことで深いネットワークを構築します。はじめは、各ニューロンは入力に対してランダムに反応するので、でたらめな値を出力をします。モデルに訓練用のデータを与え、学習を行うモデルはXを入力として受け取り、yを出力します。このとき出力Yと正解データ(教師ラベル)Tの間の差ΔEを小さくするように、誤差逆伝播法という方法で自動的に各ニューロンの重みを調整します。多量の画像などの生データXと正解データTを与えることで繰り返し重みが調整され、次第に求めたい出力が得られるようになります。うまく学習が進むと、適切な予測値を返すモデルができます。分類したいデータをモデルに渡す以上のような流れで、深層学習による分類ができます。深層学習において、各ニューロンが何に反応しているかは調べないとわかりません。逆に言うと、深層学習を用いれば具体的な分類の手順がわからなくても分類や回帰のモデルが作れるため、とても便利な手法であると言えます。"

text27 = "このchapterでは、KerasというPythonのライブラリを使って実際に以下のようなニューラルネットワークモデルを実装し、深層学習の入門として定番の手書き数字の分類を行います。流れとしては、データを用意ニューラルネットワークモデルの構築モデルにデータを与え学習させるモデルの分類精度を評価です。最後に実際に手書き数字の画像を渡して予測される値を見てみます。"

text28 = "今回は以下のような形のニューラルネットワークを作ります。このニューラルネットワークは、全てのニューロンが前の層のニューロンに結合している 全結合層 と呼ばれる層を2つもっただけの、シンプルなネットワーク構造になっています。 このネットワークの このようなある程度深さのあるニューラルネットワークを、 ディープニューラルネットワーク と呼びます。 入力を請け負う層を 入力層 、 出力をする層を 出力層 、入力層と出力層の間の層を 隠れ層 と言います。今回のモデルでは、入力には28x28のモノクロ画像を一次元配列に平坦化した784次元のベクトルを渡します。出力は10次元のベクトルです。 この縦に並んだベクトルのひとつひとつの要素を ノード と呼び、その次元数のことを ノード数 と呼びます。 手書き数字を0~9の連続値に分類するのではなく、0~9の10個のクラスに分類すると考えるのが自然であるため、出力ユニットの数を1でなく10にします。正解が7の画像データに対する教師データtは図のように、クラスラベルが7のところだけ値が1となり、それ以外の値が0となります。このようなデータのことをone-hotベクトルと言います。"

text29 = "このchapterでは、KerasというPythonのライブラリを使います。KerasはTensorFlowのラッパーライブラリで、TensorFlowをそのまま使うよりも 直感的でより簡潔にコードを書くこと ができます。TensorFlowはGoogle社によって開発された、機械学習用のオープンソースソフトウェアライブラリです。ラッパーというのは、もともとある他のシステムに対し、そのシステムを内包してより使いやすくしたもののことをいいます。"

text30 = "手書き数字のデータセットにはMNISTというデータセットを用います。MNISTには、膨大な数の手書き数字画像とそれぞれの画像に対し「０～９」で示された正解ラベルが含まれています。MNISTはYann LeCun's websiteで公開されていますが、Kerasで以下のコードを実行することで比較的簡単にローカル（ご自身のPC）にダウンロードできます。このコードは、はじめて実行する際はネットからデータのダウンロードを行います。すでにローカルにダウンロードされた状態で実行すると、ローカルからデータの読み込みが行えます。Xが大量の画像データ、yが大量の教師ラベルのデータを意味します。trainはモデルの学習用のデータ、testはモデルの性能を評価する際に使うデータです。ただしtrainデータとtestデータには、データとして本質的な違いはありません。"

text31 = "Kerasでは、まずモデルを管理するインスタンスを作り、addメソッドで層を一層ずつ定義していきます。インスタンスを作ります。以下のようにaddメソッドを用いてモデルの層を一層ずつ定義します。ユニット数128の全結合層を定義しています。各全結合層の出力には、次のようにして 活性化関数 と呼ばれる関数を適用します。これは本来動物の神経の発火に相当するような仕組みです。シグモイド関数 sigmoid やReLU関数 relu などを設定できます。詳しくはchapter2で扱います。最後にコンパイルメソッド compile() を用いてどのような学習処理を行うのかを設定して、モデルの生成が終了します。様々なパラメータがありますが詳しくはchapter2で扱います。はじめはネットワークモデルの構築のイメージがよくわからないと思うので、次の問題を見て流れを理解してください。"

text32 = "モデルに訓練データを渡して学習を行います。以下のようにfitメソッドを使います。X_train、y_trainは、学習用の入力データと教師データです。verbose は指定した数字によって学習の進捗度合いを表示するかしないかを指定でき、 verbose=1 と入力することで、学習等の進捗度合いを出力し verbose=0 にすると進捗度合いを出力しません。epochsで、同じデータセットを使って何回繰り返し学習を行うかを指定します。詳しくは、chapter2の反復学習についてのセッションで学びます。fitメソッドでは、学習用のデータ（トレーニングデータ）を順にモデルに入力し、 出力と教師データとの間の差が小さくなるよう少しずつ各ニューロンの重みを更新します。これによって誤差が減少していき、モデルの予測精度が向上します。"

text33 = "訓練データを用いて学習を行い、モデルのチューニングが無事に進みました。しかし、モデルが、訓練データのみに通用する手法を学習してしまっている可能性もあるため、これだけではモデルの性能を正しく評価することはできません。そこで、ここでは 学習に用いなかったテストデータを用いてモデルに分類をさせ、モデルの評価 を行います。モデルにテストデータを渡した時の分類の精度を、 汎化精度 といいます。汎化精度の計算には以下のように evaluateメソッド を使います。X_test, y_test は評価用の入力データと教師データです。evaluateメソッド では、損失関数の値と正解率が取得でき、上の例の場合両方ともscoreに格納されます。テストデータは汎化精度の計算のためにあり、テストデータで学習を行うことは望ましくありません。"

text34 = "modelの predictメソッド を使って予測値を取得できます。例えば X_test の初めの画像１枚の数字を予測するには以下のようにします。 (predict は複数枚の画像を引数に取ることを想定しているため、画像一枚を予測させる場合は次元に注意する必要があります。）predictメソッド の出力は10次元あるので、 argmax関数 を使って、一番大きい値を返すニューロンの場所を取得しています。"

text35 = "深層学習手法を使うと、分類あるいは回帰のアルゴリズムをほとんど自動的に生成できるためとても便利です。また、ニューラルネットワークモデルはいろいろな場面に適用させることができ汎用的です。しかし、ネットワークを構成する際に人が調整するべきパラメーターがいくつか存在します。これらは ハイパーパラメータ と呼ばれます。以下は、chapter1のMNIST分類のコードに少しだけ変更を加え、またいくつかのパラメーターを明示した典型的な深層学習手法のコードです。以下のコードのどこがハイパーパラメータに相当するのかを見ていきます。（metricsは評価関数なので、学習自体には関係ありません。評価関数については機械学習概論を参照してください。）上記のようにハイパーパラメータはたくさんあります。ハイパーパラメータは自動で変更できないものです。これらを適切に設定しないと正しく学習が行われません。自分で新しくモデルを作る時には最適なハイパーパラメータを吟味する必要があります。このchapterではそれぞれのハイパーパラメータの意味を理解し、自分でネットワークを構成、調整ができるようにしていきます。"

text36 = "ネットワークの構造（隠れ層の数、隠れ層のユニット数）は自由に決めて生成することができます。一般に、隠れ層やユニット数を多くすると、多彩な関数が表現できるようになります。しかし、隠れ層が多くなると、入力層に近い重みを適切に更新するのが難しく学習がなかなか進みにくくなったり、隠れ層のユニット数が多くなると重要性の低い特徴量を抽出してしまい過学習(汎化性能が低くなった状態)をしやすくなるなど、適切にネットワークの構造を設定する必要があります。ネットワーク構造は理論で裏付けて定めることが難しく、実際には他の似たような実装例を参考にするなど経験に基づいて決定される傾向があります。"

text37 = "ドロップアウト は、 過学習を防ぎモデルの精度をあげるための手法の一つ です。ドロップアウトを使うと、ユニットの一部が学習のたびにランダムに削除（より正確には0で上書き）されます。これにより、ニューラルネットは特定のニューロンの存在に依存できなくなり、より 汎用的な（学習データ以外でも通用しやすい）特徴を学習する ようになります。 その結果、学習データに対する過学習を防ぐことができます。ドロップアウトは以下のようにして使います。ここでrateは削除するユニットの割合です。ドロップアウトを使う位置、引数のrateはともにハイパーパラメータです。"

text38 = "活性化関数 とは、主に全結合層の後に適用する関数で、もともとニューロンの発火に相当していたものです。全結合層では、入力を線形変換したものを出力しますが、 活性化関数を用いることで非線形性をもたせます 。活性化関数を使わない場合、以下のような一本の直線で分離できない（線形分離不可能）データは分類できないことが数学的にわかっています。非線形性をもたせることで、適切に学習が進めば線形分離不可能なモデルでも必ず分類することができます。活性化関数もハイパーパラメータです。よく使われる活性化関数はいくつかあり、適切に選ぶ必要があります。"

text39 = "活性化関数として用いられる関数の1つに シグモイド関数 というものがあり、この関数は次式で与えられます。青いグラフがシグモイド関数で、オレンジ色のグラフがシグモイド関数の導関数です。"

text40 = "もうひとつ活性化関数によく用いられる ReLU（ランプ関数） というものについて説明します。ReLUはRectified Linear Unitの略で次式のような関数です。青いグラフがReLUで、オレンジ色のグラフがReLUの導関数です。"

text41 = "学習時に、モデルの出力と教師データとの差（間違え具合）を評価する関数を 損失関数（誤差関数） といいます。損失関数には 二乗誤差 や クロスエントロピー誤差 などが用いられます。この損失関数を最小化するように誤差逆伝播法という手法で各層の重みは更新されます。損失関数としてなぜ正解率を使わないのか疑問に思うかもしれません。確かに正解率を使うことはできなくはないですが、モデルがどの程度間違えているかやどういう間違え方（どのクラスだと誤認したのか）をしているかなどを総合的に評価するために、二乗誤差やクロスエントロピー誤差を損失関数として使うのが一般的です。"

text42 = "二乗誤差 は、最小二乗法として統計学など様々な分野で用いられる誤差関数です。連続値の評価に優れているため主に回帰モデルの誤差関数 として使われます。上式のはそれぞれ、予測ラベル、正解ラベルを表しています。"

text43 = "クロスエントロピー誤差 は、 二値分類の評価に特化しているため、主に分類モデルの誤差関数 として使われます。それでは、この関数がどのような特性をもつのかみていきましょう。のときはほぼ0で、は正の無限大です。のときは正の無限大で、はほぼ0です。のときは 0.69... ~ 0 の値を取ることが簡単な計算で求まります。したがっては、が大きいとき極端に大きな値を返し、が小さいとき0に近い値をとることがわかります。分類の学習において、予測ラベルy_iyと正解ラベルの値は近いほど良いのでこの関数は有用です。 これらのことから、クロスエントロピー誤差は、 0~1の2つの数の差を評価する上で合理的な関数 であると言えます。"

text44 = "重みの更新は、誤差関数を各重みで微分した値を元に、更新すべき方向とどの程度更新するかを決めます。微分によって求めた値を、 学習率、エポック数、過去の重みの更新量など を踏まえてどのように重みの更新に反映するかを定めるのが 最適化関数 です。最適化関数はハイパーパラメータです。 上図が示すように、最適化関数にはいくつか種類があり、正しく選択しないと学習に悪影響を及ぼします。"

text45 = "学習率 とは、 各層の重みを一度にどの程度変更するかを決めるハイパーパラメーター です。以下は、最小化を行おうとしているモデルと、学習率が与える影響を図示したものです。右上の点が初期値です。学習率が低すぎて、ほどんど更新が進んでいません。適切な学習率のため、少ない回数で値が収束しています。収束はしますが、値が大きいため、更新の仕方に無駄があります。学習率が大きすぎて、値が発散してしまっています。（上側に更新されており、値がどんどん大きくなっています。）このように、 損失関数に対して適切な学習率を設定する必要 があります。"

text46 = "モデルの学習を行う際、一度にモデルに渡す入力データの数は変えることができます。一度に渡すデータの数を、 バッチサイズ といい、これもハイパーパラメータです。一度に複数のデータを渡した時、モデルはそれぞれのデータでの損失と損失関数の勾配（重みをどのように更新するべきか）を求めますが、重みの更新は、１回のみ、求めた勾配の平均を使って行われます。複数のデータを用いて重みの更新を行うことで、極端に変わったデータの影響をあまり受けずに済み、また並列計算が行えるので計算時間を短縮することができます。一方、複数のデータを用いて重みの更新を行うと、極端な重みの更新が発生しなくなり、損失関数の局所解から抜け出せなくなる恐れがあります。癖の強いデータが多い時はバッチサイズを大きくする、同じようなデータが多いときはバッチサイズを小さくする などと、 バッチサイズをうまく調整する必要があります。バッチサイズを1とする手法をオンライン学習(確率的勾配法)バッチサイズを全データ数とする手法をバッチ学習（最急降下法）これらの中間となる手法をミニバッチ学習と言います。"

text47 = "一般に、モデルの精度をあげるため同じ訓練データを使って何度か学習させるということを行います。これを 反復学習 といいます。この学習を行う回数を エポック数 といい、これもハイパーパラメータです。エポック数は大きくすればモデルの精度が上がり続ける、というものではありません。正解率は途中から伸びなくなるだけでなく、繰り返し学習をすることで損失関数を最小化させようとして過学習が起こります。適切なタイミングで学習を打ち切ることが必要となってきます。"

text = text1 + text2 + text3 + text4 + text5 + text6 + text7 + text8 + text9 + text10 + text11 + text12 + text13 + text14 + text15 + text16 + text17 + text18 + text19 + text20 + text21 + text22# + text23 + text24 + text25 + text26 + text27 + text28 + text29 + text10 + text31 + text32 + text33 + text34 + text35 + text36 + text37 + text38 + text39 + text40 + text41 + text42 + text43 + text44 + text45 + text46 + text47 
